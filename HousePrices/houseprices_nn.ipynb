{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr/local/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# future functions\n",
    "from __future__ import print_function \n",
    "\n",
    "# core scipy and numpy\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "# pandas \n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "pd.options.display.max_rows = 1000\n",
    "pd.options.display.max_columns = 135\n",
    "\n",
    "# encoder\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "# manifold for embedding analysis\n",
    "from sklearn import manifold\n",
    "\n",
    "# Cross validation \n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Linear models \n",
    "from sklearn import linear_model\n",
    "\n",
    "# Forests\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor\n",
    "\n",
    "# SVR\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "# KNN\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# PCA\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# vowpal wabbit\n",
    "from vowpalwabbit.sklearn_vw import VWRegressor\n",
    "\n",
    "# combinations with categorical features\n",
    "from itertools import combinations\n",
    "\n",
    "# matplotlib \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# seaborn \n",
    "import seaborn as sns \n",
    "\n",
    "# python helpers \n",
    "from collections import namedtuple\n",
    "from copy import copy\n",
    "\n",
    "# neural network\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Merge, Reshape\n",
    "from keras.layers.embeddings import Embedding\n",
    "\n",
    "# XGboost for gradient-boosted decision trees\n",
    "import xgboost as xgb\n",
    "\n",
    "# logging\n",
    "import logging\n",
    "logging.basicConfig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loadfile = lambda x: pd.read_csv(x, index_col=0)\n",
    "\n",
    "# check column data for skew \n",
    "get_skew = lambda x: sp.stats.skewtest(x.dropna())[1]<0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Files = namedtuple('Files',['train','test'])\n",
    "RawData = namedtuple('RawData',['train','test'])\n",
    "ProcessedData = namedtuple('ProcessedData',['train','test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wrapper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class SklearnWrapper(object):\n",
    "    def __init__(self, clf, seed=2, params={}):\n",
    "        try:\n",
    "            params['random_state'] = seed\n",
    "            self.clf = clf(**params)\n",
    "        except:\n",
    "            del params['random_state'] \n",
    "            self.clf = clf(**params)\n",
    "\n",
    "    def train(self, x_train, y_train):\n",
    "        xtr = preprocessing_X(x_train)\n",
    "        ytr = preprocessing_Y(y_train).ravel()\n",
    "        self.clf.fit(xtr, ytr)\n",
    "\n",
    "    def predict(self, x):\n",
    "        xte = preprocessing_X(x)\n",
    "        return self.clf.predict(xte)\n",
    "\n",
    "\n",
    "class XgbWrapper:\n",
    "    def __init__(self, seed=2, params=None):\n",
    "        self.param = params\n",
    "        self.param['seed'] = seed\n",
    "        self.nrounds = params.pop('nrounds', 250)\n",
    "\n",
    "    def train(self, x_train, y_train):\n",
    "        xtr = preprocessing_X(x_train)\n",
    "        ytr = preprocessing_Y(y_train).ravel()\n",
    "        dtrain = xgb.DMatrix(xtr, label=ytr)\n",
    "        self.gbdt = xgb.train(self.param, dtrain, self.nrounds)\n",
    "\n",
    "    def predict(self, x):\n",
    "        xte = preprocessing_X(x)\n",
    "        return self.gbdt.predict(xgb.DMatrix(xte))\n",
    "\n",
    "\n",
    "class NnWrapper:\n",
    "    def __init__(self, model, emb=True, nb_epoch=16, batch_size=8):\n",
    "        self.model = copy(model)\n",
    "        self.nb_epoch = nb_epoch\n",
    "        self.batch_size = batch_size\n",
    "        self.emb = emb\n",
    "    \n",
    "    def train(self, x_train, y_train):\n",
    "        if self.emb:\n",
    "            xtr = nn_preprocessing_X(x_train)\n",
    "        else:\n",
    "            xtr = preprocessing_X(x_train)\n",
    "        ytr = preprocessing_Y(y_train).ravel()\n",
    "        self.model.fit(xtr, ytr, \n",
    "                 nb_epoch = self.nb_epoch,\n",
    "                 batch_size = self.batch_size,\n",
    "                 verbose = 0)\n",
    "    \n",
    "    def predict(self, x):\n",
    "        if self.emb:\n",
    "            xte = nn_preprocessing_X(x)\n",
    "        else:\n",
    "            xte = preprocessing_X(x)\n",
    "        return self.model.predict(xte).ravel()\n",
    "\n",
    "\n",
    "def get_oof(clf):\n",
    "    '''\n",
    "        via:\n",
    "        https://www.kaggle.com/eliotbarr/house-prices-\n",
    "        advanced-regression-techniques/stacking-starter/code\n",
    "    '''\n",
    "    oof_train = np.zeros((ntrain,))\n",
    "    oof_test = np.zeros((ntest,))\n",
    "    oof_test_skf = np.empty((NFOLDS, ntest))\n",
    "\n",
    "    for i, (train_index, test_index) in enumerate(kf.split(X_train)):\n",
    "        x_tr = X_train.iloc[train_index]\n",
    "        y_tr = y_train.iloc[train_index]\n",
    "        x_te = X_train.iloc[test_index]\n",
    "\n",
    "        clf.train(x_tr, y_tr)\n",
    "\n",
    "        oof_train[test_index] = clf.predict(x_te)\n",
    "        oof_test_skf[i, :] = clf.predict(X_test)\n",
    "\n",
    "    oof_test[:] = oof_test_skf.mean(axis=0)\n",
    "    return oof_train.reshape(-1, 1), oof_test.reshape(-1, 1)\n",
    "\n",
    "\n",
    "get_rmse = lambda x,y: np.sqrt(np.mean(((x.ravel()*max_y) - np.log(y.ravel()+1))**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load raw data\n",
    "rawfiles = Files(train='Data/train.csv.gz',\n",
    "            test='Data/test.csv.gz')\n",
    "raw = RawData(train=loadfile(rawfiles.train),\n",
    "              test=loadfile(rawfiles.test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# concatenate all data \n",
    "cols = [ c for c in raw.train.columns if c != 'SalePrice' ]\n",
    "full = pd.concat((raw.train.loc[:, cols],\n",
    "                     raw.test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### analyze full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/numpy/lib/function_base.py:3834: RuntimeWarning: Invalid value encountered in percentile\n",
      "  RuntimeWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>LowQualFinSF</th>\n",
       "      <th>GrLivArea</th>\n",
       "      <th>BsmtFullBath</th>\n",
       "      <th>BsmtHalfBath</th>\n",
       "      <th>FullBath</th>\n",
       "      <th>HalfBath</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>KitchenAbvGr</th>\n",
       "      <th>TotRmsAbvGrd</th>\n",
       "      <th>Fireplaces</th>\n",
       "      <th>GarageYrBlt</th>\n",
       "      <th>GarageCars</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2919.000000</td>\n",
       "      <td>2433.000000</td>\n",
       "      <td>2919.000000</td>\n",
       "      <td>2919.000000</td>\n",
       "      <td>2919.000000</td>\n",
       "      <td>2919.000000</td>\n",
       "      <td>2919.000000</td>\n",
       "      <td>2896.000000</td>\n",
       "      <td>2918.000000</td>\n",
       "      <td>2918.000000</td>\n",
       "      <td>2918.000000</td>\n",
       "      <td>2918.000000</td>\n",
       "      <td>2919.000000</td>\n",
       "      <td>2919.000000</td>\n",
       "      <td>2919.000000</td>\n",
       "      <td>2919.000000</td>\n",
       "      <td>2917.000000</td>\n",
       "      <td>2917.000000</td>\n",
       "      <td>2919.000000</td>\n",
       "      <td>2919.000000</td>\n",
       "      <td>2919.000000</td>\n",
       "      <td>2919.000000</td>\n",
       "      <td>2919.000000</td>\n",
       "      <td>2919.000000</td>\n",
       "      <td>2760.000000</td>\n",
       "      <td>2918.000000</td>\n",
       "      <td>2918.000000</td>\n",
       "      <td>2919.000000</td>\n",
       "      <td>2919.000000</td>\n",
       "      <td>2919.000000</td>\n",
       "      <td>2919.000000</td>\n",
       "      <td>2919.000000</td>\n",
       "      <td>2919.000000</td>\n",
       "      <td>2919.000000</td>\n",
       "      <td>2919.000000</td>\n",
       "      <td>2919.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>57.137718</td>\n",
       "      <td>69.305795</td>\n",
       "      <td>10168.114080</td>\n",
       "      <td>6.089072</td>\n",
       "      <td>5.564577</td>\n",
       "      <td>1971.312778</td>\n",
       "      <td>1984.264474</td>\n",
       "      <td>102.201312</td>\n",
       "      <td>441.423235</td>\n",
       "      <td>49.582248</td>\n",
       "      <td>560.772104</td>\n",
       "      <td>1051.777587</td>\n",
       "      <td>1159.581706</td>\n",
       "      <td>336.483727</td>\n",
       "      <td>4.694416</td>\n",
       "      <td>1500.759849</td>\n",
       "      <td>0.429894</td>\n",
       "      <td>0.061364</td>\n",
       "      <td>1.568003</td>\n",
       "      <td>0.380267</td>\n",
       "      <td>2.860226</td>\n",
       "      <td>1.044536</td>\n",
       "      <td>6.451524</td>\n",
       "      <td>0.597122</td>\n",
       "      <td>1978.113406</td>\n",
       "      <td>1.766621</td>\n",
       "      <td>472.874572</td>\n",
       "      <td>93.709832</td>\n",
       "      <td>47.486811</td>\n",
       "      <td>23.098321</td>\n",
       "      <td>2.602261</td>\n",
       "      <td>16.062350</td>\n",
       "      <td>2.251799</td>\n",
       "      <td>50.825968</td>\n",
       "      <td>6.213087</td>\n",
       "      <td>2007.792737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>42.517628</td>\n",
       "      <td>23.344905</td>\n",
       "      <td>7886.996359</td>\n",
       "      <td>1.409947</td>\n",
       "      <td>1.113131</td>\n",
       "      <td>30.291442</td>\n",
       "      <td>20.894344</td>\n",
       "      <td>179.334253</td>\n",
       "      <td>455.610826</td>\n",
       "      <td>169.205611</td>\n",
       "      <td>439.543659</td>\n",
       "      <td>440.766258</td>\n",
       "      <td>392.362079</td>\n",
       "      <td>428.701456</td>\n",
       "      <td>46.396825</td>\n",
       "      <td>506.051045</td>\n",
       "      <td>0.524736</td>\n",
       "      <td>0.245687</td>\n",
       "      <td>0.552969</td>\n",
       "      <td>0.502872</td>\n",
       "      <td>0.822693</td>\n",
       "      <td>0.214462</td>\n",
       "      <td>1.569379</td>\n",
       "      <td>0.646129</td>\n",
       "      <td>25.574285</td>\n",
       "      <td>0.761624</td>\n",
       "      <td>215.394815</td>\n",
       "      <td>126.526589</td>\n",
       "      <td>67.575493</td>\n",
       "      <td>64.244246</td>\n",
       "      <td>25.188169</td>\n",
       "      <td>56.184365</td>\n",
       "      <td>35.663946</td>\n",
       "      <td>567.402211</td>\n",
       "      <td>2.714762</td>\n",
       "      <td>1.314964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>1300.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1872.000000</td>\n",
       "      <td>1950.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>334.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>334.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1895.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2006.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7478.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1953.500000</td>\n",
       "      <td>1965.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>876.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1126.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2007.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9453.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1973.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1082.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1444.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2008.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>70.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11570.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2001.000000</td>\n",
       "      <td>2004.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1387.500000</td>\n",
       "      <td>704.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1743.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2009.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>190.000000</td>\n",
       "      <td>313.000000</td>\n",
       "      <td>215245.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>5644.000000</td>\n",
       "      <td>1526.000000</td>\n",
       "      <td>2336.000000</td>\n",
       "      <td>6110.000000</td>\n",
       "      <td>5095.000000</td>\n",
       "      <td>2065.000000</td>\n",
       "      <td>1064.000000</td>\n",
       "      <td>5642.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2207.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1488.000000</td>\n",
       "      <td>1424.000000</td>\n",
       "      <td>742.000000</td>\n",
       "      <td>1012.000000</td>\n",
       "      <td>508.000000</td>\n",
       "      <td>576.000000</td>\n",
       "      <td>800.000000</td>\n",
       "      <td>17000.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        MSSubClass  LotFrontage        LotArea  OverallQual  OverallCond  \\\n",
       "count  2919.000000  2433.000000    2919.000000  2919.000000  2919.000000   \n",
       "mean     57.137718    69.305795   10168.114080     6.089072     5.564577   \n",
       "std      42.517628    23.344905    7886.996359     1.409947     1.113131   \n",
       "min      20.000000    21.000000    1300.000000     1.000000     1.000000   \n",
       "25%      20.000000          NaN    7478.000000     5.000000     5.000000   \n",
       "50%      50.000000          NaN    9453.000000     6.000000     5.000000   \n",
       "75%      70.000000          NaN   11570.000000     7.000000     6.000000   \n",
       "max     190.000000   313.000000  215245.000000    10.000000     9.000000   \n",
       "\n",
       "         YearBuilt  YearRemodAdd   MasVnrArea   BsmtFinSF1   BsmtFinSF2  \\\n",
       "count  2919.000000   2919.000000  2896.000000  2918.000000  2918.000000   \n",
       "mean   1971.312778   1984.264474   102.201312   441.423235    49.582248   \n",
       "std      30.291442     20.894344   179.334253   455.610826   169.205611   \n",
       "min    1872.000000   1950.000000     0.000000     0.000000     0.000000   \n",
       "25%    1953.500000   1965.000000          NaN          NaN          NaN   \n",
       "50%    1973.000000   1993.000000          NaN          NaN          NaN   \n",
       "75%    2001.000000   2004.000000          NaN          NaN          NaN   \n",
       "max    2010.000000   2010.000000  1600.000000  5644.000000  1526.000000   \n",
       "\n",
       "         BsmtUnfSF  TotalBsmtSF     1stFlrSF     2ndFlrSF  LowQualFinSF  \\\n",
       "count  2918.000000  2918.000000  2919.000000  2919.000000   2919.000000   \n",
       "mean    560.772104  1051.777587  1159.581706   336.483727      4.694416   \n",
       "std     439.543659   440.766258   392.362079   428.701456     46.396825   \n",
       "min       0.000000     0.000000   334.000000     0.000000      0.000000   \n",
       "25%            NaN          NaN   876.000000     0.000000      0.000000   \n",
       "50%            NaN          NaN  1082.000000     0.000000      0.000000   \n",
       "75%            NaN          NaN  1387.500000   704.000000      0.000000   \n",
       "max    2336.000000  6110.000000  5095.000000  2065.000000   1064.000000   \n",
       "\n",
       "         GrLivArea  BsmtFullBath  BsmtHalfBath     FullBath     HalfBath  \\\n",
       "count  2919.000000   2917.000000   2917.000000  2919.000000  2919.000000   \n",
       "mean   1500.759849      0.429894      0.061364     1.568003     0.380267   \n",
       "std     506.051045      0.524736      0.245687     0.552969     0.502872   \n",
       "min     334.000000      0.000000      0.000000     0.000000     0.000000   \n",
       "25%    1126.000000           NaN           NaN     1.000000     0.000000   \n",
       "50%    1444.000000           NaN           NaN     2.000000     0.000000   \n",
       "75%    1743.500000           NaN           NaN     2.000000     1.000000   \n",
       "max    5642.000000      3.000000      2.000000     4.000000     2.000000   \n",
       "\n",
       "       BedroomAbvGr  KitchenAbvGr  TotRmsAbvGrd   Fireplaces  GarageYrBlt  \\\n",
       "count   2919.000000   2919.000000   2919.000000  2919.000000  2760.000000   \n",
       "mean       2.860226      1.044536      6.451524     0.597122  1978.113406   \n",
       "std        0.822693      0.214462      1.569379     0.646129    25.574285   \n",
       "min        0.000000      0.000000      2.000000     0.000000  1895.000000   \n",
       "25%        2.000000      1.000000      5.000000     0.000000          NaN   \n",
       "50%        3.000000      1.000000      6.000000     1.000000          NaN   \n",
       "75%        3.000000      1.000000      7.000000     1.000000          NaN   \n",
       "max        8.000000      3.000000     15.000000     4.000000  2207.000000   \n",
       "\n",
       "        GarageCars   GarageArea   WoodDeckSF  OpenPorchSF  EnclosedPorch  \\\n",
       "count  2918.000000  2918.000000  2919.000000  2919.000000    2919.000000   \n",
       "mean      1.766621   472.874572    93.709832    47.486811      23.098321   \n",
       "std       0.761624   215.394815   126.526589    67.575493      64.244246   \n",
       "min       0.000000     0.000000     0.000000     0.000000       0.000000   \n",
       "25%            NaN          NaN     0.000000     0.000000       0.000000   \n",
       "50%            NaN          NaN     0.000000    26.000000       0.000000   \n",
       "75%            NaN          NaN   168.000000    70.000000       0.000000   \n",
       "max       5.000000  1488.000000  1424.000000   742.000000    1012.000000   \n",
       "\n",
       "         3SsnPorch  ScreenPorch     PoolArea       MiscVal       MoSold  \\\n",
       "count  2919.000000  2919.000000  2919.000000   2919.000000  2919.000000   \n",
       "mean      2.602261    16.062350     2.251799     50.825968     6.213087   \n",
       "std      25.188169    56.184365    35.663946    567.402211     2.714762   \n",
       "min       0.000000     0.000000     0.000000      0.000000     1.000000   \n",
       "25%       0.000000     0.000000     0.000000      0.000000     4.000000   \n",
       "50%       0.000000     0.000000     0.000000      0.000000     6.000000   \n",
       "75%       0.000000     0.000000     0.000000      0.000000     8.000000   \n",
       "max     508.000000   576.000000   800.000000  17000.000000    12.000000   \n",
       "\n",
       "            YrSold  \n",
       "count  2919.000000  \n",
       "mean   2007.792737  \n",
       "std       1.314964  \n",
       "min    2006.000000  \n",
       "25%    2007.000000  \n",
       "50%    2008.000000  \n",
       "75%    2009.000000  \n",
       "max    2010.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x11abcd650>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAArgAAAHxCAYAAACGf88WAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIiLyKUxwiYiIiMinMMElIiIiIp/y/wGU+o6VU8Uk5wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11abb4c10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(full.LotFrontage.dropna())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data processing / cleansing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2919, 79)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categorical combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create lookup for numeric categorical columns\n",
    "numeric_categorical = [\n",
    "    'MSSubClass',\n",
    "    'YearBuilt',\n",
    "    'YearRemodAdd',\n",
    "    'MoSold',\n",
    "    'YrSold',\n",
    "    'GarageYrBlt',\n",
    "    'OverallQual',\n",
    "    'OverallCond',\n",
    "    'MiscVal',\n",
    "]\n",
    "\n",
    "# categorical column list\n",
    "categorical_cols = list(full.dtypes[full.dtypes == \"object\"].index)\n",
    "categorical_cols += numeric_categorical\n",
    "\n",
    "# continuous column list\n",
    "continuous_cols = list(full.dtypes[full.dtypes != \"object\"].index)\n",
    "continuous_cols = [ c for c in continuous_cols if c not in numeric_categorical and c!='SalePrice' ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### imputing, log-transforms, encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n, m = full.shape\n",
    "\n",
    "# store important objects\n",
    "label_encoders = {}\n",
    "categorical_col_nums = []\n",
    "\n",
    "# loop through columns and delete crap columns\n",
    "for col, col_data in full.iteritems():\n",
    "    \n",
    "    # count the nulls\n",
    "    nans = np.sum(col_data.isnull())\n",
    "    if nans*1.0 / n > 0.2:\n",
    "        \n",
    "        # drop columns that suck\n",
    "        del full[col]\n",
    "        if col in categorical_cols:\n",
    "            categorical_cols.remove(col)\n",
    "\n",
    "        elif col in continuous_cols:    \n",
    "            continuous_cols.remove(col)\n",
    "        \n",
    "        if col in numeric_categorical:\n",
    "            numeric_categorical.remove(col)\n",
    "\n",
    "\n",
    "# second loop through columns to process data \n",
    "for col, col_data in full.iteritems():\n",
    "    \n",
    "    # handle categorical data\n",
    "    if col_data.dtype == object or col in numeric_categorical:\n",
    "\n",
    "        # impute missing values \n",
    "        col_data = col_data.fillna(col_data.value_counts().index[0])\n",
    "\n",
    "        # encode categorical values\n",
    "        le = LabelEncoder()\n",
    "        col_data = le.fit_transform(col_data)\n",
    "        categorical_col_nums.append(full.columns.get_loc(col))\n",
    "        label_encoders[col] = le\n",
    "\n",
    "        # store column \n",
    "        full.loc[:, col] = col_data\n",
    "\n",
    "    # handle numeric data\n",
    "    else:\n",
    "\n",
    "        # check skew \n",
    "        if get_skew(full[col]):\n",
    "            full.loc[:, col] = np.log1p(full[col])\n",
    "            full.loc[:, col] = np.log1p(full[col])\n",
    "\n",
    "        # handle nulls \n",
    "        nans = np.sum(col_data.isnull())\n",
    "        if nans>0:\n",
    "            full.loc[:, col] = full[col].fillna(np.median(full[col].dropna()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup standard scaler and one hot encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# standard scaler\n",
    "continous_scaler = StandardScaler()\n",
    "c = continous_scaler.fit_transform(full.loc[:, continuous_cols].as_matrix())\n",
    "\n",
    "# minmax \n",
    "mm_scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "m = mm_scaler.fit_transform(c)\n",
    "\n",
    "# transform data in full dataset\n",
    "full.loc[:, continuous_cols] = m \n",
    "\n",
    "# create one hot encoder\n",
    "ohe = OneHotEncoder(categorical_features=categorical_col_nums)\n",
    "o = ohe.fit_transform(full.as_matrix())\n",
    "\n",
    "# pca for continuous columns\n",
    "pca_cont_n = 1\n",
    "pca_cont = PCA(n_components=pca_cont_n)\n",
    "_ = pca_cont.fit(m)\n",
    "\n",
    "# pca for ohe columns\n",
    "pca_ohe_n = 1\n",
    "pca_ohe = PCA(n_components=pca_ohe_n)\n",
    "_ = pca_ohe.fit(o.A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Processed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>Neighborhood</th>\n",
       "      <th>Condition1</th>\n",
       "      <th>Condition2</th>\n",
       "      <th>BldgType</th>\n",
       "      <th>HouseStyle</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>RoofStyle</th>\n",
       "      <th>RoofMatl</th>\n",
       "      <th>Exterior1st</th>\n",
       "      <th>Exterior2nd</th>\n",
       "      <th>MasVnrType</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>ExterQual</th>\n",
       "      <th>ExterCond</th>\n",
       "      <th>Foundation</th>\n",
       "      <th>BsmtQual</th>\n",
       "      <th>BsmtCond</th>\n",
       "      <th>BsmtExposure</th>\n",
       "      <th>BsmtFinType1</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinType2</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>Heating</th>\n",
       "      <th>HeatingQC</th>\n",
       "      <th>CentralAir</th>\n",
       "      <th>Electrical</th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>LowQualFinSF</th>\n",
       "      <th>GrLivArea</th>\n",
       "      <th>BsmtFullBath</th>\n",
       "      <th>BsmtHalfBath</th>\n",
       "      <th>FullBath</th>\n",
       "      <th>HalfBath</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>KitchenAbvGr</th>\n",
       "      <th>KitchenQual</th>\n",
       "      <th>TotRmsAbvGrd</th>\n",
       "      <th>Functional</th>\n",
       "      <th>Fireplaces</th>\n",
       "      <th>GarageType</th>\n",
       "      <th>GarageYrBlt</th>\n",
       "      <th>GarageFinish</th>\n",
       "      <th>GarageCars</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>GarageQual</th>\n",
       "      <th>GarageCond</th>\n",
       "      <th>PavedDrive</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.049771</td>\n",
       "      <td>-0.150812</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>110</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0.729236</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.785715</td>\n",
       "      <td>5</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.654186</td>\n",
       "      <td>0.801380</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.231546</td>\n",
       "      <td>0.899983</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.237589</td>\n",
       "      <td>0.210909</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.545719</td>\n",
       "      <td>0.420763</td>\n",
       "      <td>0.496609</td>\n",
       "      <td>0.210909</td>\n",
       "      <td>2</td>\n",
       "      <td>0.435695</td>\n",
       "      <td>6</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>94</td>\n",
       "      <td>1</td>\n",
       "      <td>0.444037</td>\n",
       "      <td>0.879093</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.610744</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.104840</td>\n",
       "      <td>-0.098820</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>83</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.822919</td>\n",
       "      <td>5</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.746688</td>\n",
       "      <td>0.844306</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.058886</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.026408</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.420763</td>\n",
       "      <td>0.545719</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.496609</td>\n",
       "      <td>0.210909</td>\n",
       "      <td>3</td>\n",
       "      <td>0.156522</td>\n",
       "      <td>6</td>\n",
       "      <td>0.09805</td>\n",
       "      <td>1</td>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.444037</td>\n",
       "      <td>0.856234</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.801593</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.015700</td>\n",
       "      <td>-0.035094</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>108</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0.700430</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.741087</td>\n",
       "      <td>5</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.803491</td>\n",
       "      <td>0.809512</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.176525</td>\n",
       "      <td>0.901650</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.267197</td>\n",
       "      <td>0.210909</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.545719</td>\n",
       "      <td>0.420763</td>\n",
       "      <td>0.496609</td>\n",
       "      <td>0.210909</td>\n",
       "      <td>2</td>\n",
       "      <td>0.156522</td>\n",
       "      <td>6</td>\n",
       "      <td>0.09805</td>\n",
       "      <td>1</td>\n",
       "      <td>92</td>\n",
       "      <td>1</td>\n",
       "      <td>0.444037</td>\n",
       "      <td>0.892407</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.537776</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.110878</td>\n",
       "      <td>-0.100935</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.635783</td>\n",
       "      <td>5</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.831471</td>\n",
       "      <td>0.787191</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.143497</td>\n",
       "      <td>0.885296</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.240377</td>\n",
       "      <td>0.210909</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.098050</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.496609</td>\n",
       "      <td>0.210909</td>\n",
       "      <td>2</td>\n",
       "      <td>0.307695</td>\n",
       "      <td>6</td>\n",
       "      <td>0.09805</td>\n",
       "      <td>5</td>\n",
       "      <td>89</td>\n",
       "      <td>2</td>\n",
       "      <td>0.694293</td>\n",
       "      <td>0.899306</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.500297</td>\n",
       "      <td>0.825103</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.140377</td>\n",
       "      <td>0.058366</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>107</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0.811980</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.776930</td>\n",
       "      <td>5</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.819133</td>\n",
       "      <td>0.833741</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.012596</td>\n",
       "      <td>0.924698</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.406482</td>\n",
       "      <td>0.210909</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.545719</td>\n",
       "      <td>0.420763</td>\n",
       "      <td>0.650432</td>\n",
       "      <td>0.210909</td>\n",
       "      <td>2</td>\n",
       "      <td>0.546260</td>\n",
       "      <td>6</td>\n",
       "      <td>0.09805</td>\n",
       "      <td>1</td>\n",
       "      <td>91</td>\n",
       "      <td>1</td>\n",
       "      <td>0.694293</td>\n",
       "      <td>0.932096</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.737601</td>\n",
       "      <td>0.669594</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    MSSubClass  MSZoning  LotFrontage   LotArea  Street  LotShape  \\\n",
       "Id                                                                  \n",
       "1            5         3    -0.049771 -0.150812       1         3   \n",
       "2            0         3     0.104840 -0.098820       1         3   \n",
       "3            5         3    -0.015700 -0.035094       1         0   \n",
       "4            6         3    -0.110878 -0.100935       1         0   \n",
       "5            5         3     0.140377  0.058366       1         0   \n",
       "\n",
       "    LandContour  Utilities  LotConfig  LandSlope  Neighborhood  Condition1  \\\n",
       "Id                                                                           \n",
       "1             3          0          4          0             5           2   \n",
       "2             3          0          2          0            24           1   \n",
       "3             3          0          4          0             5           2   \n",
       "4             3          0          0          0             6           2   \n",
       "5             3          0          2          0            15           2   \n",
       "\n",
       "    Condition2  BldgType  HouseStyle  OverallQual  OverallCond  YearBuilt  \\\n",
       "Id                                                                          \n",
       "1            2         0           5            6            4        110   \n",
       "2            2         0           2            5            7         83   \n",
       "3            2         0           5            6            4        108   \n",
       "4            2         0           5            6            4         25   \n",
       "5            2         0           5            7            4        107   \n",
       "\n",
       "    YearRemodAdd  RoofStyle  RoofMatl  Exterior1st  Exterior2nd  MasVnrType  \\\n",
       "Id                                                                            \n",
       "1             53          1         1           12           13           1   \n",
       "2             26          1         1            8            8           2   \n",
       "3             52          1         1           12           13           1   \n",
       "4             20          1         1           13           15           2   \n",
       "5             50          1         1           12           13           1   \n",
       "\n",
       "    MasVnrArea  ExterQual  ExterCond  Foundation  BsmtQual  BsmtCond  \\\n",
       "Id                                                                     \n",
       "1     0.729236          2          4           2         2         3   \n",
       "2    -1.000000          3          4           1         2         3   \n",
       "3     0.700430          2          4           2         2         3   \n",
       "4    -1.000000          3          4           0         3         1   \n",
       "5     0.811980          2          4           2         2         3   \n",
       "\n",
       "    BsmtExposure  BsmtFinType1  BsmtFinSF1  BsmtFinType2  BsmtFinSF2  \\\n",
       "Id                                                                     \n",
       "1              3             2    0.785715             5        -1.0   \n",
       "2              1             0    0.822919             5        -1.0   \n",
       "3              2             2    0.741087             5        -1.0   \n",
       "4              3             0    0.635783             5        -1.0   \n",
       "5              0             2    0.776930             5        -1.0   \n",
       "\n",
       "    BsmtUnfSF  TotalBsmtSF  Heating  HeatingQC  CentralAir  Electrical  \\\n",
       "Id                                                                       \n",
       "1    0.654186     0.801380        1          0           1           4   \n",
       "2    0.746688     0.844306        1          0           1           4   \n",
       "3    0.803491     0.809512        1          0           1           4   \n",
       "4    0.831471     0.787191        1          2           1           4   \n",
       "5    0.819133     0.833741        1          0           1           4   \n",
       "\n",
       "    1stFlrSF  2ndFlrSF  LowQualFinSF  GrLivArea  BsmtFullBath  BsmtHalfBath  \\\n",
       "Id                                                                            \n",
       "1  -0.231546  0.899983          -1.0   0.237589      0.210909     -1.000000   \n",
       "2   0.058886 -1.000000          -1.0   0.026408     -1.000000      0.420763   \n",
       "3  -0.176525  0.901650          -1.0   0.267197      0.210909     -1.000000   \n",
       "4  -0.143497  0.885296          -1.0   0.240377      0.210909     -1.000000   \n",
       "5  -0.012596  0.924698          -1.0   0.406482      0.210909     -1.000000   \n",
       "\n",
       "    FullBath  HalfBath  BedroomAbvGr  KitchenAbvGr  KitchenQual  TotRmsAbvGrd  \\\n",
       "Id                                                                              \n",
       "1   0.545719  0.420763      0.496609      0.210909            2      0.435695   \n",
       "2   0.545719 -1.000000      0.496609      0.210909            3      0.156522   \n",
       "3   0.545719  0.420763      0.496609      0.210909            2      0.156522   \n",
       "4   0.098050 -1.000000      0.496609      0.210909            2      0.307695   \n",
       "5   0.545719  0.420763      0.650432      0.210909            2      0.546260   \n",
       "\n",
       "    Functional  Fireplaces  GarageType  GarageYrBlt  GarageFinish  GarageCars  \\\n",
       "Id                                                                              \n",
       "1            6    -1.00000           1           94             1    0.444037   \n",
       "2            6     0.09805           1           67             1    0.444037   \n",
       "3            6     0.09805           1           92             1    0.444037   \n",
       "4            6     0.09805           5           89             2    0.694293   \n",
       "5            6     0.09805           1           91             1    0.694293   \n",
       "\n",
       "    GarageArea  GarageQual  GarageCond  PavedDrive  WoodDeckSF  OpenPorchSF  \\\n",
       "Id                                                                            \n",
       "1     0.879093           4           4           2   -1.000000     0.610744   \n",
       "2     0.856234           4           4           2    0.801593    -1.000000   \n",
       "3     0.892407           4           4           2   -1.000000     0.537776   \n",
       "4     0.899306           4           4           2   -1.000000     0.500297   \n",
       "5     0.932096           4           4           2    0.737601     0.669594   \n",
       "\n",
       "    EnclosedPorch  3SsnPorch  ScreenPorch  PoolArea  MiscVal  MoSold  YrSold  \\\n",
       "Id                                                                             \n",
       "1       -1.000000       -1.0         -1.0      -1.0        0       1       2   \n",
       "2       -1.000000       -1.0         -1.0      -1.0        0       4       1   \n",
       "3       -1.000000       -1.0         -1.0      -1.0        0       8       2   \n",
       "4        0.825103       -1.0         -1.0      -1.0        0       1       0   \n",
       "5       -1.000000       -1.0         -1.0      -1.0        0      11       2   \n",
       "\n",
       "    SaleType  SaleCondition  SalePrice  \n",
       "Id                                      \n",
       "1          8              4     208500  \n",
       "2          8              4     181500  \n",
       "3          8              4     223500  \n",
       "4          8              0     140000  \n",
       "5          8              4     250000  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create processed dataset\n",
    "train = pd.concat((full.loc[ raw.train.index, :], raw.train.SalePrice), axis=1)\n",
    "test = full.loc[ raw.test.index, :] \n",
    "processed = ProcessedData( train = train ,\n",
    "                           test = test )\n",
    "processed.train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Outliers "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "outliers = [  30,   88,  197,  462,  495,  523,  557,  632,  691,  825,  874,\n",
    "             898,  968,  970, 1169, 1170, 1182, 1423, 1432, 1453 ] # from outlier analysis\n",
    "outlier_ids = raw.train.index.isin(outliers)\n",
    "processed = ProcessedData(train=processed.train.loc[~outlier_ids ,:],\n",
    "                            test=processed.test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categorical field analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "categorical_field_analysis = []\n",
    "for c in categorical_cols:\n",
    "    # get pct freq coverage of top value \n",
    "    v = full[c].value_counts()\n",
    "    first_pct = v.iloc[0]*1.0/sum(v)\n",
    "\n",
    "    # get count of distinct values\n",
    "    distinct_vals = set(full[c].values)\n",
    "    d_cnt = len(distinct_vals)\n",
    "\n",
    "    # calculate logical freq  \n",
    "    logical_pct = 1.0/d_cnt\n",
    "        \n",
    "    # append\n",
    "    categorical_field_analysis.append((c, first_pct, logical_pct, d_cnt))\n",
    "\n",
    "categorical_field_analysis = pd.DataFrame(categorical_field_analysis,\n",
    "                                 columns=['Cat_Col',\n",
    "                                          'First_Freq',\n",
    "                                          'Logical_Freq',\n",
    "                                          'Distinct_Val_Cnt',])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@np.vectorize\n",
    "def choose_m(freq, n):\n",
    "    for i in range(1,n+1):\n",
    "        if freq>=(1-float(i)/n):\n",
    "            x = i\n",
    "            break\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "categorical_field_analysis['m'] =\\\n",
    "choose_m(categorical_field_analysis.First_Freq,\\\n",
    "categorical_field_analysis.Distinct_Val_Cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cat_Col</th>\n",
       "      <th>First_Freq</th>\n",
       "      <th>Logical_Freq</th>\n",
       "      <th>Distinct_Val_Cnt</th>\n",
       "      <th>m</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MSZoning</td>\n",
       "      <td>0.777321</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Street</td>\n",
       "      <td>0.995889</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LotShape</td>\n",
       "      <td>0.636862</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LandContour</td>\n",
       "      <td>0.898253</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Utilities</td>\n",
       "      <td>0.999657</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LotConfig</td>\n",
       "      <td>0.730730</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LandSlope</td>\n",
       "      <td>0.951696</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Neighborhood</td>\n",
       "      <td>0.151764</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>25</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Condition1</td>\n",
       "      <td>0.860226</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Condition2</td>\n",
       "      <td>0.989723</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>BldgType</td>\n",
       "      <td>0.830764</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>HouseStyle</td>\n",
       "      <td>0.503940</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>RoofStyle</td>\n",
       "      <td>0.791367</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>RoofMatl</td>\n",
       "      <td>0.985269</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Exterior1st</td>\n",
       "      <td>0.351490</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Exterior2nd</td>\n",
       "      <td>0.347722</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>16</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>MasVnrType</td>\n",
       "      <td>0.605002</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ExterQual</td>\n",
       "      <td>0.615964</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ExterCond</td>\n",
       "      <td>0.869476</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Foundation</td>\n",
       "      <td>0.448099</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>BsmtQual</td>\n",
       "      <td>0.467283</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>BsmtCond</td>\n",
       "      <td>0.920863</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>BsmtExposure</td>\n",
       "      <td>0.680370</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>BsmtFinType1</td>\n",
       "      <td>0.318602</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>BsmtFinType2</td>\n",
       "      <td>0.881466</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Heating</td>\n",
       "      <td>0.984584</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>HeatingQC</td>\n",
       "      <td>0.511477</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>CentralAir</td>\n",
       "      <td>0.932854</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Electrical</td>\n",
       "      <td>0.915382</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>KitchenQual</td>\n",
       "      <td>0.511477</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Functional</td>\n",
       "      <td>0.931483</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>GarageType</td>\n",
       "      <td>0.644056</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>GarageFinish</td>\n",
       "      <td>0.475848</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>GarageQual</td>\n",
       "      <td>0.946557</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>GarageCond</td>\n",
       "      <td>0.963686</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>PavedDrive</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>SaleType</td>\n",
       "      <td>0.865365</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>SaleCondition</td>\n",
       "      <td>0.822885</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>MSSubClass</td>\n",
       "      <td>0.369647</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>16</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>YearBuilt</td>\n",
       "      <td>0.048647</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>118</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>YearRemodAdd</td>\n",
       "      <td>0.123672</td>\n",
       "      <td>0.016393</td>\n",
       "      <td>61</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>MoSold</td>\n",
       "      <td>0.172319</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>YrSold</td>\n",
       "      <td>0.237067</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>GarageYrBlt</td>\n",
       "      <td>0.103118</td>\n",
       "      <td>0.009709</td>\n",
       "      <td>103</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>OverallQual</td>\n",
       "      <td>0.282631</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>OverallCond</td>\n",
       "      <td>0.563549</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>MiscVal</td>\n",
       "      <td>0.964714</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>38</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Cat_Col  First_Freq  Logical_Freq  Distinct_Val_Cnt    m\n",
       "0        MSZoning    0.777321      0.200000                 5    2\n",
       "1          Street    0.995889      0.500000                 2    1\n",
       "2        LotShape    0.636862      0.250000                 4    2\n",
       "3     LandContour    0.898253      0.250000                 4    1\n",
       "4       Utilities    0.999657      0.500000                 2    1\n",
       "5       LotConfig    0.730730      0.200000                 5    2\n",
       "6       LandSlope    0.951696      0.333333                 3    1\n",
       "7    Neighborhood    0.151764      0.040000                25   22\n",
       "8      Condition1    0.860226      0.111111                 9    2\n",
       "9      Condition2    0.989723      0.125000                 8    1\n",
       "10       BldgType    0.830764      0.200000                 5    1\n",
       "11     HouseStyle    0.503940      0.125000                 8    4\n",
       "12      RoofStyle    0.791367      0.166667                 6    2\n",
       "13       RoofMatl    0.985269      0.125000                 8    1\n",
       "14    Exterior1st    0.351490      0.066667                15   10\n",
       "15    Exterior2nd    0.347722      0.062500                16   11\n",
       "16     MasVnrType    0.605002      0.250000                 4    2\n",
       "17      ExterQual    0.615964      0.250000                 4    2\n",
       "18      ExterCond    0.869476      0.200000                 5    1\n",
       "19     Foundation    0.448099      0.166667                 6    4\n",
       "20       BsmtQual    0.467283      0.250000                 4    3\n",
       "21       BsmtCond    0.920863      0.250000                 4    1\n",
       "22   BsmtExposure    0.680370      0.250000                 4    2\n",
       "23   BsmtFinType1    0.318602      0.166667                 6    5\n",
       "24   BsmtFinType2    0.881466      0.166667                 6    1\n",
       "25        Heating    0.984584      0.166667                 6    1\n",
       "26      HeatingQC    0.511477      0.200000                 5    3\n",
       "27     CentralAir    0.932854      0.500000                 2    1\n",
       "28     Electrical    0.915382      0.200000                 5    1\n",
       "29    KitchenQual    0.511477      0.250000                 4    2\n",
       "30     Functional    0.931483      0.142857                 7    1\n",
       "31     GarageType    0.644056      0.166667                 6    3\n",
       "32   GarageFinish    0.475848      0.333333                 3    2\n",
       "33     GarageQual    0.946557      0.200000                 5    1\n",
       "34     GarageCond    0.963686      0.200000                 5    1\n",
       "35     PavedDrive    0.904762      0.333333                 3    1\n",
       "36       SaleType    0.865365      0.111111                 9    2\n",
       "37  SaleCondition    0.822885      0.166667                 6    2\n",
       "38     MSSubClass    0.369647      0.062500                16   11\n",
       "39      YearBuilt    0.048647      0.008475               118  113\n",
       "40   YearRemodAdd    0.123672      0.016393                61   54\n",
       "41         MoSold    0.172319      0.083333                12   10\n",
       "42         YrSold    0.237067      0.200000                 5    4\n",
       "43    GarageYrBlt    0.103118      0.009709               103   93\n",
       "44    OverallQual    0.282631      0.100000                10    8\n",
       "45    OverallCond    0.563549      0.111111                 9    4\n",
       "46        MiscVal    0.964714      0.026316                38    2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(categorical_field_analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NN model with entity embedding\n",
    "\n",
    "Choose reshape size for each categorical column. Push continuous columns through, as-is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### model topology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def gen_emb_nn_model(seed=2):\n",
    "    np.random.seed(seed)\n",
    "    models = []\n",
    "\n",
    "    for i, vals in categorical_field_analysis.T.iteritems():\n",
    "\n",
    "        # gather reshaping components\n",
    "        m = vals.Distinct_Val_Cnt\n",
    "        new_m = vals.m\n",
    "\n",
    "        # special cases \n",
    "        if vals.Cat_Col == 'YearBuilt':\n",
    "            new_m = 20\n",
    "        elif vals.Cat_Col == 'GarageYrBlt':\n",
    "            new_m = 10\n",
    "        elif vals.Cat_Col == 'YearRemodAdd':\n",
    "            new_m = 10\n",
    "        elif vals.Cat_Col == 'Neighborhood':\n",
    "            new_m = 15\n",
    "        elif vals.Cat_Col == 'HouseStyle':\n",
    "            new_m = 6\n",
    "\n",
    "        # create embedding for each feature\n",
    "        entity_model = Sequential()\n",
    "        entity_model.add(Embedding(m, new_m, input_length=1))\n",
    "        entity_model.add(Reshape(target_shape=(new_m,)))\n",
    "        models.append(entity_model)\n",
    "\n",
    "    n,m = full[continuous_cols].shape\n",
    "    m += pca_cont_n\n",
    "    continuous_model = Sequential()\n",
    "    continuous_model.add(Dense(m, input_dim=m))\n",
    "    models.append(continuous_model)\n",
    "\n",
    "    emb_model = Sequential()\n",
    "    emb_model.add(Merge(models, mode='concat'))\n",
    "    emb_model.add(Dropout(0.1))\n",
    "    emb_model.add(Dense(64, init='uniform'))\n",
    "    emb_model.add(Activation('relu'))\n",
    "    emb_model.add(Dropout(0.3))\n",
    "    emb_model.add(Dense(64, init='uniform'))\n",
    "    emb_model.add(Activation('relu'))\n",
    "    emb_model.add(Dropout(0.3))\n",
    "    emb_model.add(Dense(32, init='uniform'))\n",
    "    emb_model.add(Activation('relu'))\n",
    "    emb_model.add(Dropout(0.1))\n",
    "    emb_model.add(Dense(1))\n",
    "    emb_model.add(Activation('sigmoid'))\n",
    "    emb_model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return copy(emb_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vanilla NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# vanilla NN \n",
    "def gen_vanilla_nn(seed=2):\n",
    "    np.random.seed(seed)\n",
    "    n, m = preprocessing_X(X_train).shape\n",
    "    vanilla_nn_model = Sequential()\n",
    "    vanilla_nn_model.add(Dense(1500, init='uniform', input_shape=(m,)))\n",
    "    vanilla_nn_model.add(Activation('tanh'))\n",
    "    vanilla_nn_model.add(Dropout(0.3))\n",
    "    vanilla_nn_model.add(Dense(1500, init='uniform'))\n",
    "    vanilla_nn_model.add(Activation('tanh'))\n",
    "    vanilla_nn_model.add(Dropout(0.3))\n",
    "    vanilla_nn_model.add(Dense(1))\n",
    "    vanilla_nn_model.add(Activation('sigmoid'))\n",
    "    vanilla_nn_model.add(Dropout(0.01))\n",
    "    vanilla_nn_model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return copy(vanilla_nn_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_y = np.log1p(processed.train.SalePrice)\n",
    "max_y = np.max(_y)\n",
    "\n",
    "\n",
    "def nn_preprocessing_X(X_dat):\n",
    "    X_out = []\n",
    "    \n",
    "    # categorical columns\n",
    "    for c in categorical_cols:\n",
    "        d = X_dat.loc[:, c].as_matrix()\n",
    "        X_out.append(d)\n",
    "    \n",
    "    # continuous columns\n",
    "    continuous_dat = X_dat.loc[:, continuous_cols].as_matrix()\n",
    "    \n",
    "    # pca continuous \n",
    "    pca_Xdat_cont = pca_cont.transform(continuous_dat)\n",
    "    \n",
    "    X_out.append(np.concatenate((continuous_dat, pca_Xdat_cont), axis=1))\n",
    "    return X_out\n",
    "\n",
    "\n",
    "def preprocessing_X(X_dat):\n",
    "    X_dat = X_dat.copy()\n",
    "    \n",
    "    # continuous columns\n",
    "    continuous_dat = X_dat.loc[:, continuous_cols].as_matrix()\n",
    "    \n",
    "    # pca continuous \n",
    "    pca_Xdat_cont = pca_cont.transform(continuous_dat)\n",
    "                             \n",
    "    # one hot encode \n",
    "    X_dat = ohe.transform(X_dat.as_matrix()).A\n",
    "    \n",
    "    # pca ohe \n",
    "    pca_Xdat_ohe = pca_ohe.transform(X_dat)\n",
    "    \n",
    "    return np.concatenate((X_dat, pca_Xdat_cont, pca_Xdat_ohe), axis=1)\n",
    "\n",
    "\n",
    "def preprocessing_Y(y_dat):\n",
    "    return np.log(y_dat.values+1)/max_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 75)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed.train.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ntrain = processed.train.shape[0]\n",
    "ntest = processed.test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-663610569a55>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0memb_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_emb_nn_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mNN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNnWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memb_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mnn_oof_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnn_oof_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_oof\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0mtrain_models\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn_oof_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mtest_models\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn_oof_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-6f7b2824dcc1>\u001b[0m in \u001b[0;36mget_oof\u001b[0;34m(clf)\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mx_te\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_tr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0moof_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_te\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-6f7b2824dcc1>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, x_train, y_train)\u001b[0m\n\u001b[1;32m     51\u001b[0m                  \u001b[0mnb_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnb_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m                  \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m                  verbose = 0)\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, **kwargs)\u001b[0m\n\u001b[1;32m    662\u001b[0m                               \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 664\u001b[0;31m                               sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch)\u001b[0m\n\u001b[1;32m   1141\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1143\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1145\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, nb_epoch, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[1;32m    841\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 843\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    844\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1601\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1602\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m-> 1603\u001b[0;31m                               feed_dict=feed_dict)\n\u001b[0m\u001b[1;32m   1604\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1605\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 766\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    767\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;31m# Create a fetch handler to take care of the structure of fetches.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 951\u001b[0;31m     \u001b[0mfetch_handler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_FetchHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m     \u001b[0;31m# Run request and get response.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, graph, fetches, feeds)\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfetch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetch_mapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique_fetches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m       \u001b[0mfetch_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m       \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOperation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assert_fetchable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_targets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# set up training and test data\n",
    "cols = [c for c in processed.train.columns if c != 'SalePrice' ]\n",
    "X_train = processed.train.loc[:, cols ]\n",
    "y_train = processed.train['SalePrice']\n",
    "X_test = processed.test.loc[:, cols]\n",
    "\n",
    "# set up model arrays \n",
    "train_models = []\n",
    "test_models = []\n",
    "\n",
    "# seeds \n",
    "seeds = np.random.choice(range(100), 3, replace=False)\n",
    "\n",
    "# loop\n",
    "for s in seeds:\n",
    "    ## set up K Folds ##\n",
    "    NFOLDS = 3\n",
    "    kf = KFold(n_splits=NFOLDS, \n",
    "               shuffle=True, \n",
    "               random_state=s)\n",
    "\n",
    "    ## Categorical embedding NN models ##\n",
    "    emb_model = gen_emb_nn_model(seed=s)\n",
    "    NN = NnWrapper(emb_model, emb=True)\n",
    "    nn_oof_train, nn_oof_test = get_oof(NN)\n",
    "    train_models.append(nn_oof_train)\n",
    "    test_models.append(nn_oof_test)\n",
    "    logging.warn('NNE score, {}: {:,.4f}'.format(s, get_rmse(nn_oof_train, y_train)))\n",
    "\n",
    "    ## Vanilla NN models ##\n",
    "    vanilla_nn_model = gen_vanilla_nn(seed=s)\n",
    "    NN2 = NnWrapper(vanilla_nn_model, emb=False)\n",
    "    nn2_oof_train, nn2_oof_test = get_oof(NN2)\n",
    "    train_models.append(nn2_oof_train)\n",
    "    test_models.append(nn2_oof_test)\n",
    "    logging.warn('NNV score, {}: {:,.4f}'.format(s, get_rmse(nn2_oof_train, y_train)))\n",
    "\n",
    "    ## XGBoost ##\n",
    "    base_xgb_params ={\n",
    "        'colsample_bytree': 0.75 ,\n",
    "        'silent': 1 ,\n",
    "        'subsample': 0.5 ,\n",
    "        'learning_rate': 0.05 ,\n",
    "        'objective': 'reg:linear' ,\n",
    "        'max_depth': 4 ,\n",
    "        'num_parallel_tree': 1 ,\n",
    "        'min_child_weight': 1 ,\n",
    "        'eval_metric': 'rmse' ,\n",
    "        'nrounds': 700 ,\n",
    "    }\n",
    "    base_xgb_params['seed'] = 2\n",
    "    XG = XgbWrapper(params=base_xgb_params)\n",
    "    xgb_oof_train, xgb_oof_test = get_oof(XG)\n",
    "    train_models.append(xgb_oof_train)\n",
    "    test_models.append(xgb_oof_test)\n",
    "    logging.warn('XGB score, {}: {:,.4f}'.format(s, get_rmse(xgb_oof_train, y_train)))\n",
    "\n",
    "    ## other models ##\n",
    "    # build models\n",
    "    LS = SklearnWrapper(clf=linear_model.Lasso, params={'alpha':0.0001}, seed=s)\n",
    "    RG = SklearnWrapper(clf=linear_model.Ridge, params={'alpha':10.0}, seed=s)\n",
    "    RF = SklearnWrapper(clf=RandomForestRegressor, params={\n",
    "                                                    'n_jobs': 4,\n",
    "                                                    'n_estimators': 400,\n",
    "                                                    'max_features': 0.5,\n",
    "                                                    'max_depth': 12,\n",
    "                                                    'min_samples_leaf': 10,\n",
    "                                                }, seed=s)\n",
    "    ET = SklearnWrapper(clf=ExtraTreesRegressor, params={\n",
    "                                                    'n_jobs': 4,\n",
    "                                                    'n_estimators': 400,\n",
    "                                                    'max_features': 0.5,\n",
    "                                                    'max_depth': 12,\n",
    "                                                    'min_samples_leaf': 10,\n",
    "                                                }, seed=s)\n",
    "    SVRL = SklearnWrapper(clf=SVR, params={'kernel':'linear','C':0.0001,'epsilon':0.001},seed=s)\n",
    "    SVRB = SklearnWrapper(clf=SVR, params={'kernel':'rbf','C':1.0,'epsilon':0.001},seed=s)\n",
    "    VPW = SklearnWrapper(clf=VWRegressor, params={'l':10.0,'power_t':0.1},seed=s)\n",
    "\n",
    "    # run models\n",
    "    ls_oof_train, ls_oof_test = get_oof(LS)\n",
    "    rg_oof_train, rg_oof_test = get_oof(RG)\n",
    "    rf_oof_train, rf_oof_test = get_oof(RF)\n",
    "    et_oof_train, et_oof_test = get_oof(ET)\n",
    "    svrl_oof_train, svrl_oof_test = get_oof(SVRL)\n",
    "    svrb_oof_train, svrb_oof_test = get_oof(SVRB)\n",
    "    vpw_oof_train, vpw_oof_test = get_oof(VPW)\n",
    "\n",
    "    # append models\n",
    "    other_train_models = [\n",
    "        ls_oof_train,\n",
    "        rg_oof_train,\n",
    "        rf_oof_train,\n",
    "        et_oof_train,\n",
    "        svrl_oof_train,\n",
    "        svrb_oof_train,\n",
    "        vpw_oof_train,\n",
    "    ] \n",
    "    other_test_models = [\n",
    "        ls_oof_test,\n",
    "        rg_oof_test,\n",
    "        rf_oof_test,\n",
    "        et_oof_test,\n",
    "        svrl_oof_test,\n",
    "        svrb_oof_test,\n",
    "        vpw_oof_test,\n",
    "    ]\n",
    "    train_models += other_train_models\n",
    "    test_models += other_test_models\n",
    "    \n",
    "    # log scores\n",
    "    lookup = ['LS','RG','RF','ET','SVRL','SVRB','VPW']\n",
    "    for i, m in enumerate(other_train_models):\n",
    "        logging.warn('{} score, {}: {:,.4f}'.format(lookup[i], s, get_rmse(m, y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "need at least one array to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-5950c89066b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_models\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_models\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDMatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpreprocessing_Y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDMatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: need at least one array to concatenate"
     ]
    }
   ],
   "source": [
    "X_train = np.concatenate(train_models, axis=1)\n",
    "X_test = np.concatenate(test_models, axis=1)\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train, label=preprocessing_Y(y_train))\n",
    "dtest = xgb.DMatrix(X_test)\n",
    "\n",
    "xgb_params = {\n",
    "    'seed': 0,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'silent': 1,\n",
    "    'subsample': 0.6,\n",
    "    'learning_rate': 0.01,\n",
    "    'objective': 'reg:linear',\n",
    "    'max_depth': 1,\n",
    "    'num_parallel_tree': 1,\n",
    "    'min_child_weight': 1,\n",
    "    'eval_metric': 'rmse',\n",
    "}\n",
    "\n",
    "res = xgb.cv(xgb_params, \n",
    "             dtrain, \n",
    "             num_boost_round=1000, \n",
    "             nfold=4, \n",
    "             stratified=False,\n",
    "             early_stopping_rounds=25, \n",
    "             verbose_eval=200, \n",
    "             show_stdv=True)\n",
    "best_nrounds = res.shape[0] - 1\n",
    "xgb_final_model = xgb.train(xgb_params, dtrain, best_nrounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "calc_exp = lambda x: np.exp(x*max_y)-1\n",
    "print('Ensemble:\\t{:,.4f}+{:,.4f}'.format(calc_exp(res.iloc[-1,0]),calc_exp(res.iloc[-1,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = np.exp(xgb_final_model.predict(dtest)*max_y)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(np.vstack((raw.test.index.astype(str).ravel(), \n",
    "                                     predictions.ravel())).T,\n",
    "                          columns=['Id','SalePrice'])\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
