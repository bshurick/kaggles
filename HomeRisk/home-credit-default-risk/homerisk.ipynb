{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting homerisk_model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile homerisk_model.py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# modeling\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from pandas.api.types import is_string_dtype\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "\n",
    "MODEL_COLS = [\n",
    " 'NAME_CONTRACT_TYPE',\n",
    " 'CODE_GENDER',\n",
    " 'FLAG_OWN_CAR',\n",
    " 'FLAG_OWN_REALTY',\n",
    " 'CNT_CHILDREN',\n",
    " 'AMT_INCOME_TOTAL',\n",
    " 'AMT_CREDIT',\n",
    " 'AMT_ANNUITY',\n",
    " 'AMT_GOODS_PRICE',\n",
    " 'NAME_TYPE_SUITE',\n",
    " 'NAME_INCOME_TYPE',\n",
    " 'NAME_EDUCATION_TYPE',\n",
    " 'NAME_FAMILY_STATUS',\n",
    " 'NAME_HOUSING_TYPE',\n",
    " 'REGION_POPULATION_RELATIVE',\n",
    " 'DAYS_BIRTH',\n",
    " 'DAYS_EMPLOYED',\n",
    " 'DAYS_REGISTRATION',\n",
    " 'DAYS_ID_PUBLISH',\n",
    " 'OWN_CAR_AGE',\n",
    "#  'FLAG_MOBIL',\n",
    "#  'FLAG_EMP_PHONE',\n",
    "#  'FLAG_WORK_PHONE',\n",
    "#  'FLAG_CONT_MOBILE',\n",
    "#  'FLAG_PHONE',\n",
    "#  'FLAG_EMAIL',\n",
    " 'OCCUPATION_TYPE',\n",
    " 'CNT_FAM_MEMBERS',\n",
    " 'REGION_RATING_CLIENT',\n",
    " 'REGION_RATING_CLIENT_W_CITY',\n",
    " 'WEEKDAY_APPR_PROCESS_START',\n",
    " 'HOUR_APPR_PROCESS_START',\n",
    " 'REG_REGION_NOT_LIVE_REGION',\n",
    " 'REG_REGION_NOT_WORK_REGION',\n",
    " 'LIVE_REGION_NOT_WORK_REGION',\n",
    " 'REG_CITY_NOT_LIVE_CITY',\n",
    " 'REG_CITY_NOT_WORK_CITY',\n",
    " 'LIVE_CITY_NOT_WORK_CITY',\n",
    " 'ORGANIZATION_TYPE',\n",
    " 'EXT_SOURCE_1',\n",
    " 'EXT_SOURCE_2',\n",
    " 'EXT_SOURCE_3',\n",
    " 'APARTMENTS_AVG',\n",
    " 'BASEMENTAREA_AVG',\n",
    " 'YEARS_BEGINEXPLUATATION_AVG',\n",
    " 'YEARS_BUILD_AVG',\n",
    " 'COMMONAREA_AVG',\n",
    " 'ELEVATORS_AVG',\n",
    " 'ENTRANCES_AVG',\n",
    " 'FLOORSMAX_AVG',\n",
    " 'FLOORSMIN_AVG',\n",
    " 'LANDAREA_AVG',\n",
    " 'LIVINGAPARTMENTS_AVG',\n",
    " 'LIVINGAREA_AVG',\n",
    " 'NONLIVINGAPARTMENTS_AVG',\n",
    " 'NONLIVINGAREA_AVG',\n",
    " 'APARTMENTS_MODE',\n",
    " 'BASEMENTAREA_MODE',\n",
    " 'YEARS_BEGINEXPLUATATION_MODE',\n",
    " 'YEARS_BUILD_MODE',\n",
    " 'COMMONAREA_MODE',\n",
    " 'ELEVATORS_MODE',\n",
    " 'ENTRANCES_MODE',\n",
    " 'FLOORSMAX_MODE',\n",
    " 'FLOORSMIN_MODE',\n",
    " 'LANDAREA_MODE',\n",
    " 'LIVINGAPARTMENTS_MODE',\n",
    " 'LIVINGAREA_MODE',\n",
    " 'NONLIVINGAPARTMENTS_MODE',\n",
    " 'NONLIVINGAREA_MODE',\n",
    " 'APARTMENTS_MEDI',\n",
    " 'BASEMENTAREA_MEDI',\n",
    " 'YEARS_BEGINEXPLUATATION_MEDI',\n",
    " 'YEARS_BUILD_MEDI',\n",
    " 'COMMONAREA_MEDI',\n",
    " 'ELEVATORS_MEDI',\n",
    " 'ENTRANCES_MEDI',\n",
    " 'FLOORSMAX_MEDI',\n",
    " 'FLOORSMIN_MEDI',\n",
    " 'LANDAREA_MEDI',\n",
    " 'LIVINGAPARTMENTS_MEDI',\n",
    " 'LIVINGAREA_MEDI',\n",
    " 'NONLIVINGAPARTMENTS_MEDI',\n",
    " 'NONLIVINGAREA_MEDI',\n",
    " 'FONDKAPREMONT_MODE',\n",
    " 'HOUSETYPE_MODE',\n",
    " 'TOTALAREA_MODE',\n",
    " 'WALLSMATERIAL_MODE',\n",
    " 'EMERGENCYSTATE_MODE',\n",
    " 'OBS_30_CNT_SOCIAL_CIRCLE',\n",
    " 'DEF_30_CNT_SOCIAL_CIRCLE',\n",
    " 'OBS_60_CNT_SOCIAL_CIRCLE',\n",
    " 'DEF_60_CNT_SOCIAL_CIRCLE',\n",
    " 'DAYS_LAST_PHONE_CHANGE',\n",
    " 'FLAG_DOCUMENT_2',\n",
    " 'FLAG_DOCUMENT_3',\n",
    " 'FLAG_DOCUMENT_4',\n",
    " 'FLAG_DOCUMENT_5',\n",
    " 'FLAG_DOCUMENT_6',\n",
    " 'FLAG_DOCUMENT_7',\n",
    " 'FLAG_DOCUMENT_8',\n",
    " 'FLAG_DOCUMENT_9',\n",
    " 'FLAG_DOCUMENT_10',\n",
    " 'FLAG_DOCUMENT_11',\n",
    " 'FLAG_DOCUMENT_12',\n",
    " 'FLAG_DOCUMENT_13',\n",
    " 'FLAG_DOCUMENT_14',\n",
    " 'FLAG_DOCUMENT_15',\n",
    " 'FLAG_DOCUMENT_16',\n",
    " 'FLAG_DOCUMENT_17',\n",
    " 'FLAG_DOCUMENT_18',\n",
    " 'FLAG_DOCUMENT_19',\n",
    " 'FLAG_DOCUMENT_20',\n",
    " 'FLAG_DOCUMENT_21',\n",
    " 'AMT_REQ_CREDIT_BUREAU_HOUR',\n",
    " 'AMT_REQ_CREDIT_BUREAU_DAY',\n",
    " 'AMT_REQ_CREDIT_BUREAU_WEEK',\n",
    " 'AMT_REQ_CREDIT_BUREAU_MON',\n",
    " 'AMT_REQ_CREDIT_BUREAU_QRT',\n",
    " 'AMT_REQ_CREDIT_BUREAU_YEAR',\n",
    "    \n",
    " 'PREV_AMT_DOWN_PAYMENT_sum',\n",
    " 'PREV_AMT_DOWN_PAYMENT_mean',\n",
    " 'PREV_SK_ID_PREV_nunique',\n",
    " 'PREV_RATE_INTEREST_PRIMARY_mean',\n",
    " 'PREV_AMT_CREDIT_sum',\n",
    " 'PREV_AMT_CREDIT_mean',\n",
    " 'PREV_AMT_CREDIT_max',\n",
    " 'PREV_AMT_CREDIT_min',\n",
    " 'PREV_AMT_APPLICATION_sum',\n",
    " 'PREV_AMT_APPLICATION_mean',\n",
    " 'PREV_AMT_APPLICATION_max',\n",
    " 'PREV_AMT_APPLICATION_min',\n",
    " 'PREV_AMT_GOODS_PRICE_sum',\n",
    " 'PREV_AMT_GOODS_PRICE_mean',\n",
    " 'PREV_AMT_GOODS_PRICE_max',\n",
    " 'PREV_AMT_GOODS_PRICE_min',\n",
    " 'PREV_RATE_INTEREST_PRIVILEGED_mean',\n",
    " 'prev_pct_down',\n",
    " 'prev_pct_credit_app',\n",
    " 'lastloan_NAME_CONTRACT_TYPE',\n",
    " 'lastloan_AMT_ANNUITY',\n",
    " 'lastloan_AMT_APPLICATION',\n",
    " 'lastloan_AMT_CREDIT',\n",
    " 'lastloan_AMT_DOWN_PAYMENT',\n",
    " 'lastloan_AMT_GOODS_PRICE',\n",
    " 'lastloan_WEEKDAY_APPR_PROCESS_START',\n",
    " 'lastloan_HOUR_APPR_PROCESS_START',\n",
    " 'lastloan_FLAG_LAST_APPL_PER_CONTRACT',\n",
    " 'lastloan_NFLAG_LAST_APPL_IN_DAY',\n",
    " 'lastloan_RATE_DOWN_PAYMENT',\n",
    " 'lastloan_RATE_INTEREST_PRIMARY',\n",
    " 'lastloan_RATE_INTEREST_PRIVILEGED',\n",
    " 'lastloan_NAME_CASH_LOAN_PURPOSE',\n",
    " 'lastloan_NAME_CONTRACT_STATUS',\n",
    " 'lastloan_DAYS_DECISION',\n",
    " 'lastloan_NAME_PAYMENT_TYPE',\n",
    " 'lastloan_CODE_REJECT_REASON',\n",
    " 'lastloan_NAME_TYPE_SUITE',\n",
    " 'lastloan_NAME_CLIENT_TYPE',\n",
    " 'lastloan_NAME_GOODS_CATEGORY',\n",
    " 'lastloan_NAME_PORTFOLIO',\n",
    " 'lastloan_NAME_PRODUCT_TYPE',\n",
    " 'lastloan_CHANNEL_TYPE',\n",
    " 'lastloan_SELLERPLACE_AREA',\n",
    " 'lastloan_NAME_SELLER_INDUSTRY',\n",
    " 'lastloan_CNT_PAYMENT',\n",
    " 'lastloan_NAME_YIELD_GROUP',\n",
    " 'lastloan_PRODUCT_COMBINATION',\n",
    " 'lastloan_DAYS_FIRST_DRAWING',\n",
    " 'lastloan_DAYS_FIRST_DUE',\n",
    " 'lastloan_DAYS_LAST_DUE_1ST_VERSION',\n",
    " 'lastloan_DAYS_LAST_DUE',\n",
    " 'lastloan_DAYS_TERMINATION',\n",
    " 'lastloan_NFLAG_INSURED_ON_APPROVAL',\n",
    " 'lastloan_PREV_SK_ID_PREV_max',\n",
    "]\n",
    "TARGET_COL = 'TARGET'\n",
    "\n",
    "\n",
    "def prepare_previous_loans(filenm='./previous_application.csv.zip'):\n",
    "    AGGS = {\n",
    "        'SK_ID_PREV': ['nunique','max'] ,\n",
    "        'AMT_APPLICATION':['sum','mean','max','min',] ,\n",
    "        'AMT_CREDIT':['sum','mean','max','min',] ,\n",
    "        'AMT_DOWN_PAYMENT':['sum','mean',] ,\n",
    "        'AMT_GOODS_PRICE':['sum','mean','max','min',] ,\n",
    "        'RATE_INTEREST_PRIMARY':['mean',] ,\n",
    "        'RATE_INTEREST_PRIVILEGED':['mean',] ,\n",
    "    }\n",
    "    previous = pd.read_csv(filenm)\n",
    "    prev_aggs = previous.groupby('SK_ID_CURR').agg(AGGS)\n",
    "    prev_aggs.columns = [ 'PREV_' + '_'.join(col).strip() for col in prev_aggs.columns.values]\n",
    "    prev_aggs.reset_index(inplace=True)\n",
    "\n",
    "    # add new calculations \n",
    "    prev_aggs['prev_pct_down'] = prev_aggs.PREV_AMT_DOWN_PAYMENT_sum / prev_aggs.PREV_AMT_APPLICATION_sum\n",
    "    prev_aggs['prev_pct_credit_app'] = prev_aggs.PREV_AMT_CREDIT_sum / prev_aggs.PREV_AMT_APPLICATION_sum\n",
    "    prev_aggs.replace(np.inf, np.nan, inplace=True)\n",
    "    \n",
    "    # get last loan \n",
    "    last_loan = pd.merge(previous, prev_aggs[['PREV_SK_ID_PREV_max']], left_on=['SK_ID_PREV'],right_on=['PREV_SK_ID_PREV_max'])\n",
    "    last_loan.columns = [ 'lastloan_'+c if c not in ['SK_ID_PREV','SK_ID_CURR'] else c for c in last_loan.columns]\n",
    "\n",
    "    # merge into aggregated dataset\n",
    "    prevs_w_last = pd.merge(prev_aggs, last_loan, how='left', on=['SK_ID_CURR'], suffixes=('','_lastloan'))\n",
    "    del prevs_w_last['PREV_SK_ID_PREV_max']\n",
    "    \n",
    "    return prevs_w_last\n",
    "\n",
    "\n",
    "class RiskModel:\n",
    "    \n",
    "    \n",
    "    def __init__(self, \n",
    "                 train, \n",
    "                 test, \n",
    "                 val=pd.DataFrame([]), \n",
    "                 params={}, \n",
    "                 type='RF', \n",
    "                 rounds=0,\n",
    "                 cols=MODEL_COLS,\n",
    "                 target=TARGET_COL,\n",
    "        ):\n",
    "        ''' Initialize but do nothing\n",
    "        '''\n",
    "        self.train = train.copy()\n",
    "        self.test = test.copy()\n",
    "        self.val = val.copy()\n",
    "        self.feature_lookup = {}\n",
    "        self.feature_lookup_rev = {}\n",
    "        self.params = params\n",
    "        self.model = None\n",
    "        self.type = type\n",
    "        self.preds = None\n",
    "        self.rounds = rounds\n",
    "        self.cols = cols\n",
    "        self.target = target\n",
    "    \n",
    "    \n",
    "    def build_lookups(self):\n",
    "        ''' Build encoding lookups\n",
    "        '''\n",
    "        val_lookup = {}\n",
    "        val_lookup_rev = {}\n",
    "        for i, c in self.train.iteritems():\n",
    "\n",
    "            if is_string_dtype(c):\n",
    "                u = np.unique(c.astype('str'))\n",
    "                kv = { v:i for i, v in zip(np.arange(u.shape[0]),u) }\n",
    "                vk = { i:v for i, v in zip(np.arange(u.shape[0]),u) }\n",
    "                val_lookup[i] = kv\n",
    "                val_lookup_rev[i] = vk\n",
    "        \n",
    "        self.feature_lookup = val_lookup\n",
    "        self.feature_lookup_rev = val_lookup_rev\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def find_encoding(x, lookup):\n",
    "        \n",
    "        if x in lookup:\n",
    "            \n",
    "            return lookup[x]\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            return np.nan\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def ohe_cols(ohe, str_columns):\n",
    "        ohecols = []\n",
    "        m = ohe.feature_indices_[-1]\n",
    "        for i, ind in enumerate(ohe.feature_indices_[:-1]):\n",
    "            col = list(str_columns)[i]\n",
    "            next_ind = ohe.feature_indices_[i+1]\n",
    "            newcols = [ col+'_'+str(z) for z in range(next_ind - ind) ]\n",
    "            ohecols += newcols\n",
    "\n",
    "        return ohecols\n",
    "    \n",
    "    \n",
    "    def run_encodings(self, ohe=True, minmax=False, pca=False):\n",
    "        ''' Encode values in training data\n",
    "        '''\n",
    "        strings = []\n",
    "        is_val = self.val.shape[0] >0\n",
    "        for i, c in self.train.iteritems():\n",
    "            \n",
    "            if is_string_dtype(c):\n",
    "                \n",
    "                # add list of string columns\n",
    "                strings.append(i)\n",
    "                \n",
    "                # fill nulls with value 'nan' and encode with numeric values\n",
    "                self.train[i] = self.train[i].fillna('nan').apply(lambda x: self.find_encoding(x, self.feature_lookup[i]))\n",
    "                self.test[i] = self.test[i].fillna('nan').apply(lambda x: self.find_encoding(x, self.feature_lookup[i]))\n",
    "                \n",
    "                # check if validation dataset exists and encode if so\n",
    "                if is_val:\n",
    "                    \n",
    "                    self.val[i] = self.val[i].fillna('nan').apply(lambda x: self.find_encoding(x, self.feature_lookup[i]))\n",
    "        \n",
    "        strcols = self.train[strings].columns\n",
    "        if ohe:\n",
    "            \n",
    "            # create one hot encoder & transform data into OHE matrices\n",
    "            oh = OneHotEncoder( handle_unknown='ignore', sparse=False )\n",
    "            train_ohe = oh.fit_transform(self.train.loc[:, strings])\n",
    "            test_ohe = oh.transform(self.test.loc[:, strings].fillna(99999))\n",
    "            \n",
    "            # check if validation dataset exists, if so then transform with OHE\n",
    "            if is_val:\n",
    "                val_ohe = oh.transform(self.val.loc[:, strings].fillna(99999))\n",
    "            \n",
    "            # create names for new OHE matrix columns\n",
    "            ohecols = self.ohe_cols(oh, strcols)\n",
    "            \n",
    "            # add new OHE datasets into dataframes\n",
    "            train_ohe = pd.DataFrame(train_ohe, columns=[ohecols], index=self.train.index)\n",
    "            test_ohe = pd.DataFrame(test_ohe, columns=[ohecols], index=self.test.index)\n",
    "            self.train = pd.concat((self.train, train_ohe), axis=1)\n",
    "            self.test = pd.concat((self.test, test_ohe), axis=1)\n",
    "            \n",
    "            # check if validation dataset exists, if so concatenate results\n",
    "            if is_val:\n",
    "                val_ohe = pd.DataFrame(val_ohe, columns=[ohecols], index=self.val.index)\n",
    "                self.val = pd.concat((self.val, val_ohe), axis=1)\n",
    "            \n",
    "            # exclude original columns\n",
    "            newcols = list(set(self.cols + ohecols))\n",
    "            self.cols = [ c for c in newcols if c not in strcols ]\n",
    "        \n",
    "        if minmax:\n",
    "            \n",
    "            # scale between 0 and 1\n",
    "            mm = MinMaxScaler(feature_range=(0, 1))\n",
    "            self.train[ self.cols ] = mm.fit_transform(self.train[ self.cols ].fillna(0))\n",
    "            self.test[ self.cols ] = mm.transform(self.test[ self.cols ].fillna(0))\n",
    "            \n",
    "            if is_val:\n",
    "                self.val[ self.cols ] = mm.transform(self.val[ self.cols ].fillna(0))\n",
    "        \n",
    "        if pca:\n",
    "            \n",
    "            cumulative_variance = 0.95\n",
    "            pca_data_train = []\n",
    "            pca_data_test = []\n",
    "            \n",
    "            if is_val:\n",
    "                pca_data_val = []\n",
    "            \n",
    "            remcols = []\n",
    "            \n",
    "            for scol in strcols:\n",
    "                \n",
    "                # instantiate pca \n",
    "                pc = PCA(random_state=22)\n",
    "                \n",
    "                # find all string / ohe cols\n",
    "                scols = [ c for c in self.cols if re.search(scol, c) ]\n",
    "                \n",
    "                # remove string / ohe cols later\n",
    "                remcols += scols\n",
    "                \n",
    "                # PCA fit & transforms\n",
    "                pca_train = pc.fit_transform( self.train[ self.cols ].fillna(np.random.random()) )\n",
    "                pca_test = pc.transform( self.test[ self.cols ].fillna(np.random.random()) ) \n",
    "                \n",
    "                if is_val:\n",
    "                    pca_val = pc.transform( self.val[ self.cols ].fillna(np.random.random()) ) \n",
    "                \n",
    "                # find max point to clip off based on cumulative variance ratios\n",
    "                amax = np.argmax ( np.cumsum( pc.explained_variance_ratio_ ) > cumulative_variance )\n",
    "                cols = [ '{}_PCA_{}'.format(scol,z) for z in range(amax+1) ]\n",
    "                \n",
    "                # create dataframes to concatenate onto training dataset\n",
    "                pca_train = pd.DataFrame(pca_train[:, :amax+1], columns=cols, index=self.train.index)\n",
    "                pca_test = pd.DataFrame(pca_test[:, :amax+1], columns=cols, index=self.test.index)\n",
    "                \n",
    "                if is_val:\n",
    "                    pca_val = pd.DataFrame(pca_val[:, :amax+1], columns=cols, index=self.val.index)\n",
    "                \n",
    "                pca_data_train.append(pca_train)\n",
    "                pca_data_test.append(pca_test)\n",
    "                \n",
    "                if is_val:\n",
    "                    pca_data_val.append(pca_val)\n",
    "            \n",
    "            # concatentate all data together\n",
    "            pca_data_train = pd.concat(pca_data_train, axis=1)\n",
    "            pca_data_test = pd.concat(pca_data_test , axis=1)\n",
    "            \n",
    "            self.train = pd.concat((self.train, pca_data_train), axis=1)\n",
    "            self.test = pd.concat((self.test, pca_data_test), axis=1)\n",
    "            \n",
    "            if is_val:\n",
    "                pca_data_val = pd.concat(pca_data_val , axis=1)\n",
    "                self.val = pd.concat((self.val, pca_data_val), axis=1)\n",
    "            \n",
    "            # set up new column set without exclusion cols\n",
    "            pcacols = list(pca_data_train.columns)\n",
    "            self.cols = list(set(self.cols + pcacols))\n",
    "            self.cols = [ c for c in self.cols if c not in remcols ]\n",
    "            \n",
    "    \n",
    "    def train_model(self):\n",
    "        ''' Train a randomforest model \n",
    "        '''\n",
    "        if self.type == 'RF':\n",
    "            \n",
    "            # instantiate model\n",
    "            m = RandomForestClassifier(**self.params)\n",
    "            \n",
    "            # fit model and save\n",
    "            m.fit( self.train[ self.cols].fillna(0), self.train[self.target].values )\n",
    "            self.model = m \n",
    "        \n",
    "        if self.type == 'LR':\n",
    "            \n",
    "            lr = LogisticRegression(**self.params)\n",
    "            lr.fit( self.train[ self.cols].fillna(0), self.train[self.target].values ) \n",
    "            self.model = lr\n",
    "        \n",
    "        if self.type == 'XGB':\n",
    "            \n",
    "            dtrain = xgb.DMatrix(self.train[ self.cols], label=self.train[self.target])\n",
    "            \n",
    "            if self.val.shape[0] > 0:\n",
    "                \n",
    "                dval = xgb.DMatrix(self.val[ self.cols], label=self.val[self.target])\n",
    "                evallist  = [(dtrain,'train'), (dval,'eval')]\n",
    "                gbdt = xgb.train(\n",
    "                    self.params,\n",
    "                    dtrain,\n",
    "                    self.rounds,\n",
    "                    evallist,\n",
    "                    early_stopping_rounds = self.rounds // 10 ,\n",
    "                    verbose_eval = self.rounds // 10 ,\n",
    "                )\n",
    "                self.model = gbdt\n",
    "                \n",
    "            else:\n",
    "                \n",
    "                gbdt = xgb.train(\n",
    "                    self.params,\n",
    "                    dtrain,\n",
    "                    self.rounds,\n",
    "                )\n",
    "                self.model = gbdt\n",
    "    \n",
    "    \n",
    "    def output_predictions(self):\n",
    "        ''' \n",
    "        '''\n",
    "        if self.type == 'RF' or self.type == 'LR':\n",
    "            \n",
    "            preds = self.model.predict_proba(self.test[ self.cols].fillna(0))[:, 1]\n",
    "            return preds\n",
    "        \n",
    "        \n",
    "        if self.type == 'XGB':\n",
    "            \n",
    "            dtest = xgb.DMatrix(self.test[ self.cols])\n",
    "            preds = self.model.predict( dtest )\n",
    "            return preds\n",
    "    \n",
    "    \n",
    "    def save_predictions(self):\n",
    "        ''' Dont output, just save (for validation)\n",
    "        '''\n",
    "        if self.type == 'RF' or self.type == 'LR':\n",
    "            \n",
    "            preds = self.model.predict_proba(self.test[ self.cols].fillna(0))[:, 1]\n",
    "            self.test_preds = preds\n",
    "            \n",
    "            if self.val.shape[0] > 0:\n",
    "                \n",
    "                preds = self.model.predict_proba(self.val[ self.cols].fillna(0))[:, 1]\n",
    "                self.val_preds = preds\n",
    "                \n",
    "        \n",
    "        if self.type == 'XGB':\n",
    "            \n",
    "            dtest = xgb.DMatrix(self.test[ self.cols])\n",
    "            preds = self.model.predict( dtest )\n",
    "            self.test_preds = preds\n",
    "            \n",
    "            if self.val.shape[0] > 0:\n",
    "                \n",
    "                dval = xgb.DMatrix(self.val[ self.cols])\n",
    "                preds = self.model.predict( dval )\n",
    "                self.val_preds = preds\n",
    "    \n",
    "    \n",
    "    def run(self):\n",
    "        self.build_lookups()\n",
    "        self.run_encodings(ohe=True, minmax=True, pca=False)\n",
    "        self.train_model()\n",
    "        self.save_predictions()\n",
    "        \n",
    "        # create final output df \n",
    "        preds_df = pd.DataFrame(self.test_preds, columns=['TARGET'])\n",
    "        preds_df['SK_ID_CURR'] = self.test.SK_ID_CURR\n",
    "        self.preds_df = preds_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-auc:0.699731\teval-auc:0.694044\n",
      "Multiple eval metrics have been passed: 'eval-auc' will be used for early stopping.\n",
      "\n",
      "Will train until eval-auc hasn't improved in 140 rounds.\n",
      "[140]\ttrain-auc:0.762928\teval-auc:0.745615\n",
      "[280]\ttrain-auc:0.779498\teval-auc:0.755053\n",
      "[420]\ttrain-auc:0.789193\teval-auc:0.75868\n",
      "[560]\ttrain-auc:0.79656\teval-auc:0.760482\n",
      "[700]\ttrain-auc:0.803339\teval-auc:0.761708\n",
      "[840]\ttrain-auc:0.809187\teval-auc:0.762265\n",
      "[980]\ttrain-auc:0.814988\teval-auc:0.762876\n",
      "[1120]\ttrain-auc:0.820219\teval-auc:0.763219\n",
      "[1260]\ttrain-auc:0.825147\teval-auc:0.76329\n",
      "[1399]\ttrain-auc:0.829958\teval-auc:0.763216\n",
      "Stopping. Best iteration:\n",
      "[1259]\ttrain-auc:0.825125\teval-auc:0.763304\n",
      "\n",
      "[0]\ttrain-auc:0.697886\teval-auc:0.695864\n",
      "Multiple eval metrics have been passed: 'eval-auc' will be used for early stopping.\n",
      "\n",
      "Will train until eval-auc hasn't improved in 140 rounds.\n",
      "[140]\ttrain-auc:0.761311\teval-auc:0.753247\n",
      "[280]\ttrain-auc:0.778101\teval-auc:0.761683\n",
      "[420]\ttrain-auc:0.788318\teval-auc:0.764963\n",
      "[560]\ttrain-auc:0.795958\teval-auc:0.766522\n",
      "[700]\ttrain-auc:0.802879\teval-auc:0.767394\n",
      "[840]\ttrain-auc:0.80888\teval-auc:0.767936\n",
      "[980]\ttrain-auc:0.814802\teval-auc:0.768247\n",
      "[1120]\ttrain-auc:0.819732\teval-auc:0.768323\n",
      "[1260]\ttrain-auc:0.824643\teval-auc:0.768339\n",
      "Stopping. Best iteration:\n",
      "[1185]\ttrain-auc:0.822028\teval-auc:0.768425\n",
      "\n",
      "[0]\ttrain-auc:0.698782\teval-auc:0.695723\n",
      "Multiple eval metrics have been passed: 'eval-auc' will be used for early stopping.\n",
      "\n",
      "Will train until eval-auc hasn't improved in 140 rounds.\n",
      "[140]\ttrain-auc:0.762037\teval-auc:0.747568\n",
      "[280]\ttrain-auc:0.77869\teval-auc:0.757149\n",
      "[420]\ttrain-auc:0.788953\teval-auc:0.760742\n",
      "[560]\ttrain-auc:0.796911\teval-auc:0.762429\n",
      "[700]\ttrain-auc:0.803747\teval-auc:0.763411\n",
      "[840]\ttrain-auc:0.809773\teval-auc:0.763922\n",
      "[980]\ttrain-auc:0.815298\teval-auc:0.764272\n",
      "[1120]\ttrain-auc:0.820762\teval-auc:0.764692\n",
      "[1260]\ttrain-auc:0.825863\teval-auc:0.764868\n",
      "Stopping. Best iteration:\n",
      "[1196]\ttrain-auc:0.823596\teval-auc:0.764959\n",
      "\n",
      "[0]\ttrain-auc:0.699312\teval-auc:0.694669\n",
      "Multiple eval metrics have been passed: 'eval-auc' will be used for early stopping.\n",
      "\n",
      "Will train until eval-auc hasn't improved in 140 rounds.\n",
      "[140]\ttrain-auc:0.760938\teval-auc:0.752774\n",
      "[280]\ttrain-auc:0.777151\teval-auc:0.76249\n",
      "[420]\ttrain-auc:0.786897\teval-auc:0.766523\n",
      "[560]\ttrain-auc:0.79484\teval-auc:0.768459\n",
      "[700]\ttrain-auc:0.801709\teval-auc:0.769407\n",
      "[840]\ttrain-auc:0.807963\teval-auc:0.770082\n",
      "[980]\ttrain-auc:0.813821\teval-auc:0.770484\n",
      "[1120]\ttrain-auc:0.819208\teval-auc:0.770569\n",
      "[1260]\ttrain-auc:0.824311\teval-auc:0.77067\n",
      "Stopping. Best iteration:\n",
      "[1197]\ttrain-auc:0.82198\teval-auc:0.770725\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from homerisk_model import *\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score, log_loss\n",
    "\n",
    "train = pd.read_csv('./application_train.csv.zip')\n",
    "test = pd.read_csv('./application_test.csv.zip')\n",
    "\n",
    "# add prior loans\n",
    "priors = prepare_previous_loans()\n",
    "train = pd.merge(train, priors, on=['SK_ID_CURR'], how='left')\n",
    "test = pd.merge(test, priors, on=['SK_ID_CURR'], how='left')\n",
    "\n",
    "rf_params={\n",
    "    'n_estimators': 350,\n",
    "    'min_samples_split': 4,\n",
    "    'n_jobs': 16,\n",
    "}\n",
    "xgb_params ={\n",
    "    'silent': 1 ,\n",
    "    'booster': 'gbtree' ,\n",
    "    'objective': 'binary:logistic' ,\n",
    "    'eval_metric': 'auc' ,\n",
    "    'nthread': 16 ,\n",
    "}\n",
    "lr_params = {\n",
    "    'C': 0.001, \n",
    "    'n_jobs': 16, \n",
    "    'solver':'sag',\n",
    "}\n",
    "# prepare to show results\n",
    "results = []\n",
    "Xtrue = train[TARGET_COL].values\n",
    "\n",
    "\n",
    "xgb_params['seed'] =             22\n",
    "xgb_params['max_depth'] =        4\n",
    "xgb_params['min_child_weight'] = 2\n",
    "xgb_params['eta'] =              0.03\n",
    "xgb_params['gamma'] =            0.001\n",
    "xgb_params['colsample_bytree'] = 0.85\n",
    "xgb_params['subsample'] =        0.85\n",
    "\n",
    "xgb_params['alpha'] =            0.01\n",
    "xgb_params['lambda'] =           0.01\n",
    "\n",
    "\n",
    "K = 4\n",
    "kf = KFold(n_splits=K, shuffle=True, random_state=22)\n",
    "xgval = np.zeros(train.shape[0])\n",
    "rfval = np.zeros(train.shape[0])\n",
    "lrval = np.zeros(train.shape[0])\n",
    "xgtst = np.zeros(test.shape[0])\n",
    "rftst = np.zeros(test.shape[0])\n",
    "lrtst = np.zeros(test.shape[0])\n",
    "\n",
    "for train_index, test_index in kf.split(train):\n",
    "    \n",
    "    # set up neg/pos weightings\n",
    "    nneg = np.sum(train.iloc[train_index, :][TARGET_COL] == 0)\n",
    "    npos = np.sum(train.iloc[train_index, :][TARGET_COL] == 1)\n",
    "    weight_dict = {0:1, 1:nneg/npos}\n",
    "    \n",
    "    ## XGB\n",
    "    xgb_params['scale_pos_weight'] = nneg/npos\n",
    "    xb = RiskModel( \n",
    "        train = train.iloc[train_index,:], \n",
    "        test = test, \n",
    "        val = train.iloc[test_index], \n",
    "        params = xgb_params, \n",
    "        type = 'XGB', \n",
    "        rounds = 1400 ,\n",
    "    )\n",
    "    xb.run()\n",
    "    xgval[test_index] = xb.val_preds\n",
    "    xgtst += xb.test_preds / K\n",
    "    \n",
    "    ## RF \n",
    "    rf_params['class_weight'] = weight_dict\n",
    "    rf = RiskModel( \n",
    "        train = train.iloc[train_index,:], \n",
    "        test = test, \n",
    "        val = train.iloc[test_index], \n",
    "        params = rf_params, \n",
    "        type = 'RF' \n",
    "    )\n",
    "    rf.run()\n",
    "    rfval[test_index] = rf.val_preds\n",
    "    rftst += rf.test_preds / K\n",
    "    \n",
    "    ## LR\n",
    "    lr_params['class_weight'] = weight_dict\n",
    "    lr = RiskModel( \n",
    "        train = train.iloc[train_index,:], \n",
    "        test = test, \n",
    "        val = train.iloc[test_index], \n",
    "        params = lr_params, \n",
    "        type = 'LR' \n",
    "    )\n",
    "    lr.run()\n",
    "    lrval[test_index] = lr.val_preds\n",
    "    lrtst += lr.test_preds / K\n",
    "\n",
    "# pd.DataFrame(results, columns=['Model','ROC','LogLoss','Depth','MCW'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stack models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-auc:0.760517\teval-auc:0.761056\n",
      "Multiple eval metrics have been passed: 'eval-auc' will be used for early stopping.\n",
      "\n",
      "Will train until eval-auc hasn't improved in 80 rounds.\n",
      "[80]\ttrain-auc:0.767392\teval-auc:0.767734\n",
      "[160]\ttrain-auc:0.76922\teval-auc:0.768032\n",
      "[240]\ttrain-auc:0.77122\teval-auc:0.76808\n",
      "[320]\ttrain-auc:0.773012\teval-auc:0.768189\n",
      "Stopping. Best iteration:\n",
      "[284]\ttrain-auc:0.772222\teval-auc:0.768234\n",
      "\n",
      "[0]\ttrain-auc:0.760646\teval-auc:0.759036\n",
      "Multiple eval metrics have been passed: 'eval-auc' will be used for early stopping.\n",
      "\n",
      "Will train until eval-auc hasn't improved in 80 rounds.\n",
      "[80]\ttrain-auc:0.768009\teval-auc:0.765143\n",
      "Stopping. Best iteration:\n",
      "[50]\ttrain-auc:0.767873\teval-auc:0.765336\n",
      "\n",
      "[0]\ttrain-auc:0.761555\teval-auc:0.756467\n",
      "Multiple eval metrics have been passed: 'eval-auc' will be used for early stopping.\n",
      "\n",
      "Will train until eval-auc hasn't improved in 80 rounds.\n",
      "[80]\ttrain-auc:0.768254\teval-auc:0.763459\n",
      "[160]\ttrain-auc:0.769938\teval-auc:0.764055\n",
      "[240]\ttrain-auc:0.771891\teval-auc:0.764025\n",
      "Stopping. Best iteration:\n",
      "[173]\ttrain-auc:0.77037\teval-auc:0.764114\n",
      "\n",
      "[0]\ttrain-auc:0.759322\teval-auc:0.758846\n",
      "Multiple eval metrics have been passed: 'eval-auc' will be used for early stopping.\n",
      "\n",
      "Will train until eval-auc hasn't improved in 80 rounds.\n",
      "[80]\ttrain-auc:0.767597\teval-auc:0.76718\n",
      "[160]\ttrain-auc:0.769272\teval-auc:0.7678\n",
      "[240]\ttrain-auc:0.771315\teval-auc:0.767734\n",
      "Stopping. Best iteration:\n",
      "[183]\ttrain-auc:0.769926\teval-auc:0.767851\n",
      "\n",
      "[0]\ttrain-auc:0.760711\teval-auc:0.760866\n",
      "Multiple eval metrics have been passed: 'eval-auc' will be used for early stopping.\n",
      "\n",
      "Will train until eval-auc hasn't improved in 80 rounds.\n",
      "[80]\ttrain-auc:0.767543\teval-auc:0.767667\n",
      "[160]\ttrain-auc:0.76933\teval-auc:0.767923\n",
      "[240]\ttrain-auc:0.77143\teval-auc:0.767816\n",
      "Stopping. Best iteration:\n",
      "[172]\ttrain-auc:0.769743\teval-auc:0.767959\n",
      "\n",
      "[0]\ttrain-auc:0.760227\teval-auc:0.760129\n",
      "Multiple eval metrics have been passed: 'eval-auc' will be used for early stopping.\n",
      "\n",
      "Will train until eval-auc hasn't improved in 80 rounds.\n",
      "[80]\ttrain-auc:0.767349\teval-auc:0.768804\n",
      "[160]\ttrain-auc:0.769231\teval-auc:0.768994\n",
      "Stopping. Best iteration:\n",
      "[116]\ttrain-auc:0.768106\teval-auc:0.769149\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train['xgbval'] = xgval \n",
    "train['rfval'] = rfval\n",
    "train['lrval'] = lrval\n",
    "test['xgbval'] = xgtst\n",
    "test['rfval'] = rftst\n",
    "test['lrval'] = lrtst\n",
    "\n",
    "\n",
    "results = []\n",
    "Xtrue = train[TARGET_COL].values\n",
    "kf = KFold(n_splits=6, shuffle=True)\n",
    "stackpreds = np.zeros(train.shape[0])\n",
    "stackpreds_tst = np.zeros(test.shape[0])\n",
    "\n",
    "\n",
    "models = [('xg',xgval), ('rf',rfval), ('lr',lrval)]\n",
    "for m, Xpred in models:\n",
    "    roc = roc_auc_score(Xtrue, Xpred)\n",
    "    ll = log_loss(Xtrue, Xpred)\n",
    "    results.append((m, roc, ll))\n",
    "\n",
    "\n",
    "stack_params ={\n",
    "    'silent': 1 ,\n",
    "    'booster': 'gbtree' ,\n",
    "    'objective': 'binary:logistic' ,\n",
    "    'eval_metric': 'auc' ,\n",
    "    'nthread': 16 ,\n",
    "}\n",
    "stack_params['seed'] =             22\n",
    "stack_params['max_depth'] =        3\n",
    "stack_params['min_child_weight'] = 1\n",
    "stack_params['eta'] =              0.03\n",
    "stack_params['gamma'] =            0.0\n",
    "stack_params['colsample_bytree'] = 0.9\n",
    "stack_params['subsample'] =        0.9\n",
    "stack_params['alpha'] =            0.0\n",
    "stack_params['lambda'] =           0.0\n",
    "stack_cols = MODEL_COLS + ['xgbval','rfval','lrval']\n",
    "\n",
    "\n",
    "for train_index, test_index in kf.split(train):\n",
    "    \n",
    "    \n",
    "    mstack = RiskModel( \n",
    "        train = train.iloc[train_index], \n",
    "        test = test,\n",
    "        val = train.iloc[test_index],\n",
    "        params = stack_params, \n",
    "        type = 'XGB', \n",
    "        rounds = 800 ,\n",
    "        cols = stack_cols ,\n",
    "    )\n",
    "    mstack.run()\n",
    "    stackpreds[test_index] = mstack.val_preds\n",
    "    stackpreds_tst += mstack.test_preds / K\n",
    "\n",
    "\n",
    "roc = roc_auc_score(Xtrue, stackpreds)\n",
    "ll = log_loss(Xtrue, stackpreds)\n",
    "results.append(('stack', roc, ll))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>ROC</th>\n",
       "      <th>LogLoss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xg</td>\n",
       "      <td>0.766749</td>\n",
       "      <td>0.532339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rf</td>\n",
       "      <td>0.733380</td>\n",
       "      <td>0.256191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.731165</td>\n",
       "      <td>0.595569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>stack</td>\n",
       "      <td>0.766459</td>\n",
       "      <td>0.243825</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Model       ROC   LogLoss\n",
       "0     xg  0.766749  0.532339\n",
       "1     rf  0.733380  0.256191\n",
       "2     lr  0.731165  0.595569\n",
       "3  stack  0.766459  0.243825"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results, columns=['Model','ROC','LogLoss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create final output df \n",
    "preds_df = pd.DataFrame(stackpreds_tst, columns=['TARGET'])\n",
    "preds_df['SK_ID_CURR'] = test.SK_ID_CURR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyze predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f15f3e9f150>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEKCAYAAAACS67iAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niIgn/j8CdFf5x5Dm2gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f15f3e8fa90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(preds_df.TARGET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_df.loc[preds_df.TARGET > 1, 'TARGET'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds_df[['SK_ID_CURR','TARGET']].to_csv('submission.csv', sep=',', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.4.2 / client 1.1.0)\n",
      "Successfully submitted to Home Credit Default Risk"
     ]
    }
   ],
   "source": [
    "!gzip -f submission.csv\n",
    "!kaggle competitions submit -c home-credit-default-risk -f submission.csv.gz -m \"kfold\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
